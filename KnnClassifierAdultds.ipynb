{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXUBiZdGxySe"
      },
      "source": [
        "# KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmzy0eKTxySg"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JXWPQqWxySk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZQ57JZ-xySm"
      },
      "source": [
        "1) Get the dataset Adult (either in the UCI Repository or in Kaggle)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM9gc7RmxySo"
      },
      "source": [
        "Usaremos o file_input para dar drop em linhas que possuam valores vazios e file_input_entropy para ajustar aos valores mais frequentes de cada feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOzLi8QHxySy"
      },
      "outputs": [],
      "source": [
        "file_input.drop(columns=['fnlwgt'], inplace=True, axis=1)\n",
        "file_input_entropy.drop(columns=['fnlwgt'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbdfNyB6xyS0"
      },
      "source": [
        "2) Analyze features, missing data, and overall characteristics of the dataset (using tools in sklearn). Select features, discretize numerical features, handle missing data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkY9xg_nxyS3"
      },
      "source": [
        "Para tratar os dados, usaremos 2 formas e comparaçoe.\n",
        "1- Exclusao das linhas com valores nulos.\n",
        "2- Tratamento da informaçao nula e substituiçao pelo valor mais provavel ( Considerando a moda da feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0nA8DkIxyS8"
      },
      "outputs": [],
      "source": [
        "#Drop de linhas com workclass vazia.\n",
        "file_input.drop(file_input.index[(file_input['workclass']=='?')],axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B7TIs6cxyTB"
      },
      "outputs": [],
      "source": [
        "file_input.drop(file_input.index[(file_input['occupation']=='?')],axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ713VtYxyTD"
      },
      "outputs": [],
      "source": [
        "file_input.drop(file_input.index[(file_input['native.country']=='?')],axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d515kFodxyTF"
      },
      "source": [
        "\n",
        "Precisamos Normalizar a base que tem campos categóricos. Utilizaremos o OneHotEncoder para isso. Cada categoria vira uma coluna nova."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSje6imaxyTI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "x_full_entropy=file_input_entropy.drop(['income'],axis=1)\n",
        "y_full_entropy=file_input_entropy['income']\n",
        "y_ent=file_input_entropy['income']\n",
        "y_label = {'<=50K': 0, '>50K': 1}\n",
        "y_entropy= y_ent.replace(y_label)\n",
        "y=file_input['income']\n",
        "y_label = {'<=50K': 0, '>50K': 1}\n",
        "y = y.replace(y_label)\n",
        "y.describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-z3RSXnxyTJ"
      },
      "outputs": [],
      "source": [
        "index_categorico = [k == 'O' for k in x_full_entropy.dtypes]\n",
        "x_full_entropy.iloc[:, index_categorico]\n",
        "colunas_categoricas = x_full_entropy.columns[index_categorico]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snkDkFF4xyTK"
      },
      "outputs": [],
      "source": [
        "# tratamento de nulos do file_input_entropy\n",
        "for k in colunas_categoricas:\n",
        "    index2=file_input_entropy.index[(file_input_entropy[k]=='?')]\n",
        "    for i2 in index2:\n",
        "        file_input_entropy.replace(file_input_entropy[k][i2],file_input_entropy[k].max(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAFt2z_6xyTM"
      },
      "outputs": [],
      "source": [
        "X_categorias_entropy = file_input_entropy.drop(['income'],axis=1).iloc[:, index_categorico]\n",
        "ohe_entropy = OneHotEncoder(dtype=int).fit(X_categorias_entropy)\n",
        "X_ohe_entropy = pd.DataFrame(ohe_entropy.transform(X_categorias_entropy).toarray(), columns=ohe_entropy.get_feature_names_out())\n",
        "print(X_ohe_entropy.shape)\n",
        "X_ohe_entropy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Rp5q_8xyTO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "p = 0.3 # fraction of elements in the test set\n",
        "x_train_entropy, x_test_entropy, y_train_entropy, y_test_entropy = train_test_split(X_ohe_entropy,y_entropy, test_size = p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdeAOzyBxyTO"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "k = 6\n",
        "model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "model.fit(x_train_entropy, y_train_entropy)\n",
        "y_pred_knn_com_tratamentoNull = model.predict(x_test_entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MlbWtX9xyTP",
        "outputId": "8d5f274f-e042-4cf1-8849-871b2dd21d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuracia KNN 6  Com tratamento de dados faltantes (Coloca o de maior frequência da feature)  : 0.8197358992732112\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score_knn_tratamento = accuracy_score(y_pred_knn_com_tratamentoNull, y_test_entropy)\n",
        "print('Acuracia KNN',str(k), ' Com tratamento de dados faltantes (Coloca o de maior frequência da feature) ', ':', score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validation com\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from statistics import mean\n",
        "scores = cross_val_score(model,X_ohe_entropy,y_entropy, cv=5)\n",
        "print(\"media acuracia usando cross validation: \" + str(mean(scores)))"
      ],
      "metadata": {
        "id": "j47ADL4RTGZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5434f58-eaaf-437d-bc47-a9a311d72d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "media acuracia usando cross validation: 0.8119526256502304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4jkxIcoxyTR"
      },
      "source": [
        "### Tratamento de valores categoricos com o OneHotEncoder Para base com drop em linhas com informação faltante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWzMNvczxyTR"
      },
      "outputs": [],
      "source": [
        "index_categorico = [k == 'O' for k in x_full.dtypes]\n",
        "x_full.iloc[:, index_categorico]\n",
        "colunas_categoricas = x_full.columns[index_categorico]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSwnXpemxyTS"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "X_categorias = x_full.iloc[:, index_categorico]\n",
        "ohe = OneHotEncoder(dtype=int).fit(X_categorias)\n",
        "X_ohe = pd.DataFrame(ohe.transform(X_categorias).toarray(), columns=ohe.get_feature_names_out())\n",
        "print(X_ohe.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8P9DUtdxyTY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "p = 0.3 # fraction of elements in the test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_ohe,y, test_size = p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa6ycnhixyTY"
      },
      "outputs": [],
      "source": [
        "model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "model.fit(x_train, y_train)\n",
        "y_pred_knn_notNulls = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score_knn_notNulls = accuracy_score(y_pred_knn_notNulls, y_test)\n",
        "print('Acuracia KNN -',str(k), ' Desprezando as linhas com nulos:', score_knn_notNulls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv4e1Z2T8BKh",
        "outputId": "6ae07b92-5d46-4757-8d61-af13d06756f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuracia KNN - 6  Desprezando as linhas com nulos: 0.7992043319703834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdNu07DcxyTZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from statistics import mean\n",
        "clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "scores = cross_val_score(clf,X_ohe,y, cv=5)\n",
        "print(\"media acuracia usando cross validation: \" + str(mean(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG_BfP0QxyTd"
      },
      "source": [
        "# Other classifiers\n",
        "\n",
        "Iremos utilizar alguns outros classificadores para comparação."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine"
      ],
      "metadata": {
        "id": "9mrWPMgV6xL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "regr = svm.SVC()\n",
        "regr.fit(x_train_entropy, y_train_entropy)\n",
        "y_pred_svm=regr.predict(x_test_entropy)\n",
        "score_svm = accuracy_score(y_pred_svm, y_test_entropy)"
      ],
      "metadata": {
        "id": "_6ykAUab4L2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Randon forest"
      ],
      "metadata": {
        "id": "rfdMgziU5HE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_class= RandomForestClassifier(max_depth=20, random_state=0)\n",
        "random_forest_class.fit(x_train_entropy, y_train_entropy)\n",
        "y_pred_random_forest=random_forest_class.predict(x_test_entropy)\n",
        "score_random_forest = accuracy_score(y_pred_random_forest, y_test_entropy)\n",
        "print(score_random_forest)"
      ],
      "metadata": {
        "id": "C3QCUa5u5WTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regressão Logistica"
      ],
      "metadata": {
        "id": "yrE3TNEMENdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "clf = LogisticRegressionCV(cv=5, random_state=0).fit(x_train_entropy, y_train_entropy)\n",
        "y_pred_logistic=clf.predict(x_test_entropy)\n",
        "score_logistic = accuracy_score(y_pred_logistic, y_test_entropy)\n",
        "print(score_logistic)"
      ],
      "metadata": {
        "id": "w7qfTnCnETw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XBoost"
      ],
      "metadata": {
        "id": "rfxpnPRd5LaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgb_cl = xgb.XGBClassifier()\n",
        "xgb_cl.fit(x_train_entropy, y_train_entropy)\n",
        "y_pred_xboost = xgb_cl.predict(x_test_entropy)\n",
        "score_xboost = accuracy_score(y_pre_xboost, y_test_entropy)\n",
        "print(score_xboost)"
      ],
      "metadata": {
        "id": "qQCD6oBIgpj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fKbZVfVxyTe"
      },
      "source": [
        "# Resultados obtidos\n",
        "Nesse tópico iremos comparar a precisão, acurácia e outras métricas dos modelos e técnicas urtilizadas para classificação.\n",
        "- Comparação de acurácia de cada modelo.\n",
        "- Comparação de F_{1} Score.\n",
        "- Comparação de precisão, recall, F_score e suporte.\n",
        "O código de cálculo dos indicadores e métricas para cada classificador, ficou grande e teve que ser suprimido."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "heM1uznqZWyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1 Score para todos os classificadores\" + str(f1_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hgUAQqkatLl",
        "outputId": "bc047563-ec51-4527-d901-8149f75a6948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score para todos os classificadores\n",
            "{'Regressao logistica': 0.5941361763993216, 'Knn': 0.5410122164048866, 'SVM': 0.5952208544532946, 'Random forest': 0.19506233194817893, 'XGBoost': 0.615020137408197}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precisao, recall, Fscore e suporte para todos os classificadores\" + str(fs_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyQc7kUPZYox",
        "outputId": "f1aea4d7-a3b5-4562-8cff-443235f3ffb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisao, recall, Fscore e suporte para todos os classificadores\n",
            "{'Regressao logistica': (0.5175179400590967, 0.6973833902161547, 0.5941361763993216, None), 'Knn': (0.45799915576192485, 0.6607795371498173, 0.5410122164048866, None), 'SVM': (0.5204727733220769, 0.6950394588500564, 0.5952208544532946, None), 'Random forest': (0.16842549598986914, 0.23170731707317074, 0.19506233194817893, None), 'XGBoost': (0.5479105107640354, 0.7008639308855291, 0.615020137408197, None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Acurácia dos classificadores\"+str(acuracia_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koBHh8ngcONi",
        "outputId": "8b6af56d-9127-406c-c9a9-dd928dd3b19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia dos classificadores\n",
            "{'Regressao logistica': 0.8285392568328386, 'Knn': 0.8115467294503019, 'SVM': 0.8283345275872659, 'Random forest': 0.8265943289998976, 'XGBoost': 0.6596376292353363}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisando todos os classificadores, com o tratamento realizado nos dados, pode-se considerar que a classificação utilizando SVM e Regressão logística, apresentaram os melhores resultados, do ponto de vista de acurácia."
      ],
      "metadata": {
        "id": "CBH_hhXhfZvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aVOSNVtVhSUK"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
