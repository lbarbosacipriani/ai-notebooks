{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18993,"status":"ok","timestamp":1695220165366,"user":{"displayName":"Leonardo Cipriani","userId":"14400768154911632203"},"user_tz":180},"id":"pUKQNBpu0j5w","outputId":"21d39cb8-36aa-42c0-ae5e-c97b9118ee1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"]}],"source":["!pip install opendatasets\n","!pip install pandas"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20065,"status":"ok","timestamp":1695220200202,"user":{"displayName":"Leonardo Cipriani","userId":"14400768154911632203"},"user_tz":180},"id":"X1k-fXIzcZP2","outputId":"1442eedc-7a1f-4e43-96fe-ac622a71dc07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: leonardocipriani\n","Your Kaggle Key: ··········\n","Downloading datasethela.zip to ./datasethela\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 40.8M/40.8M [00:00<00:00, 74.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["import opendatasets as od\n","import pandas\n"," #{\"username\":\"leonardocipriani\",\"key\":\"3d5f9270a34aafb650753723a6efb2c5\"}\n","od.download(\"https://www.kaggle.com/datasets/leonardocipriani/datasethela\")\n","#od.download(\"https://www.kaggle.com/datasets/leonardocipriani/3dircadb\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19405,"status":"ok","timestamp":1691333496396,"user":{"displayName":"Leonardo Barbosa","userId":"06345230168258917960"},"user_tz":180},"id":"kvfCUvN46mtJ","outputId":"be72b1cd-2b56-4a70-e8fe-ca175abf8f9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CyKn3k8kXBpw"},"outputs":[],"source":["def impHistoria(history):\n","  print(history.history.keys())\n","  plt.plot(history.history['loss']); plt.plot(history.history['val_loss'])\n","  plt.title('model loss'); plt.ylabel('loss'); plt.xlabel('epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113570,"status":"ok","timestamp":1691334292080,"user":{"displayName":"Leonardo Barbosa","userId":"06345230168258917960"},"user_tz":180},"id":"Fbk-fB1ilP0c","outputId":"8d853ad7-dbdd-4636-8a52-ce8be4a12a07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Lendo:  /content/train.csv\n","84\n","1.0\n","Lendo:  /content/valida.csv\n","65\n","1.0\n"]}],"source":["#unet-train1.py\n","#Treina rede unet para segmentacao semantica de eliret\n","from PIL import Image\n","import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n","import cv2; import numpy as np; np.random.seed(7); import sys\n","import tensorflow.keras as keras; from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *; from tensorflow.keras.optimizers import *\n","import matplotlib.pyplot as plt\n","from skimage.transform import rescale, resize, downscale_local_mean\n","\n","tamanho_img=512\n","def impHistoria2(history):\n","  print(history.history.keys())\n","  plt.plot(history.history['accuracy']); plt.plot(history.history['val_loss'])\n","  plt.title('model loss'); plt.ylabel('loss'); plt.xlabel('epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  plt.show()\n","\n","def leCsv(nomeDir,nomeArq):\n","  print(\"Lendo: \",nomeArq); arq=open(os.path.join(nomeDir,nomeArq),\"r\")\n","  lines=arq.readlines(); arq.close(); n=len(lines)\n","  print(n)\n","  nl,nc = tamanho_img,tamanho_img\n","  AX=np.empty((n,nl,nc),dtype='uint8'); AY=np.empty((n,nl,nc),dtype='uint8')\n","  i=0\n","  for linha in lines:\n","    linha=linha.strip('\\n'); linha=linha.split(';')\n","    nomeDir='/content/drive/MyDrive/Colab Notebooks/'\n","    #print(os.path.join(nomeDir,linha[0]))\n","    AX[i]=Image.open(os.path.join(nomeDir,linha[0]))\n","    AX[i]= np.array(AX[i])\n","  #  print(AX[i])\n","  #  AX[i]=AX[i]*255/AX[i].max()\n","    AY[i]=Image.open(os.path.join(nomeDir,linha[1]))\n","    AY[i]= np.array(AY[i])\n"," #   AY[ AY>=125 ] = 255\n"," #   AY[ AY<125] = 0\n"," #   AY[i]=AY[i]*255/AY[i].max()\n"," #   f = plt.figure()\n"," #   f.add_subplot(1,4,1); plt.imshow(AX[i],cmap=\"gray\"); plt.axis('off')\n"," #   f.add_subplot(1,4,2); plt.imshow(AY[i],cmap=\"gray\"); plt.axis('off')\n"," #   plt.show(block=True)\n"," #   ax1=np.float32(AX[i].reshape(nl,nc))/255.0\n"," #   ax2=np.float32(AY[i].reshape(nl,nc))/255.0\n"," #   f = plt.figure()\n"," #   f.add_subplot(1,4,1); plt.imshow(ax1,cmap=\"gray\"); plt.axis('off')\n"," #   f.add_subplot(1,4,2); plt.imshow(ax2,cmap=\"gray\"); plt.axis('off')\n"," #   plt.show(block=True)\n","    i=i+1\n","\n","  ax= np.float32(AX)/255.0\n","  ay= np.float32(AY)/255.0 #Entre 0 e +1\n","  print(ax.max())\n","  ax = ax.reshape(n, nl, nc, 1); ay = ay.reshape(n, nl, nc, 1)\n","\n"," #   AY[i]=AY[i]*255/AY[i].max()\n","\n","  return ax, ay\n","\n","\n","#<<<<<<<<<<<<<<<<<<<< main <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n","bdDir = \"\"\n","ax, ay = leCsv(bdDir,\"/content/train.csv\")\n","vx, vy = leCsv(bdDir,\"/content/valida.csv\")\n","#qx, qy = leCsv(bdDir,\"teste.csv\")\n","outDir = \".\"; os.chdir(outDir)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyEZhR7BNQ7v"},"outputs":[],"source":["def unet(input_size = (tamanho_img,tamanho_img,1)):\n","  n=64\n","  inputs = Input(input_size)\n","  conv2 = Conv2D(n, 3, activation = 'relu', padding = 'same' )(inputs)\n","  conv2 = Conv2D(n, 3, activation = 'relu', padding = 'same' )(conv2)\n","  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","  conv3 = Conv2D(2*n, 3, activation = 'relu', padding = 'same' )(pool2)\n","  conv3 = Conv2D(2*n, 3, activation = 'relu', padding = 'same' )(conv3)\n","  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","  conv4 = Conv2D(4*n, 3, activation = 'relu', padding = 'same' )(pool3)\n","  conv4 = Conv2D(4*n, 3, activation = 'relu', padding = 'same' )(conv4)\n","  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","  conv5 = Conv2D(8*n, 3, activation = 'relu', padding = 'same' )(pool4)\n","  conv5 = Conv2D(8*n, 3, activation = 'relu', padding = 'same' )(conv5)\n","  up6 = Conv2D(4*n, 2, activation = 'relu', padding = 'same'\n","              )(UpSampling2D(size = (2,2))(conv5))\n","  merge6 = concatenate([conv4,up6], axis = 3)\n","  conv6 = Conv2D(4*n, 3, activation = 'relu', padding = 'same' )(merge6)\n","  conv6 = Conv2D(4*n, 3, activation = 'relu', padding = 'same' )(conv6)\n","  up7 = Conv2D(2*n, 2, activation = 'relu', padding = 'same'\n","              )(UpSampling2D(size = (2,2))(conv6))\n","  merge7 = concatenate([conv3,up7], axis = 3)\n","  conv7 = Conv2D(2*n, 3, activation = 'relu', padding = 'same' )(merge7)\n","  conv7 = Conv2D(2*n, 3, activation = 'relu', padding = 'same' )(conv7)\n","  up8 = Conv2D(n, 2, activation = 'relu', padding = 'same'\n","              )(UpSampling2D(size = (2,2))(conv7))\n","  merge8 = concatenate([conv2,up8], axis = 3)\n","  conv8 = Conv2D(n, 3, activation = 'relu', padding = 'same' )(merge8)\n","  conv8 = Conv2D(n, 3, activation = 'relu', padding = 'same' )(conv8)\n","  conv9 = Conv2D(1, 1, activation = 'relu', padding = 'same' )(conv8)\n","  model = Model(inputs = inputs, outputs = conv9)\n","  model.compile(optimizer = Adam(learning_rate=1e-5), loss = 'mean_squared_error',metrics=['accuracy'])\n","  from tensorflow.keras.utils import plot_model\n","  plot_model(model, to_file='unet-train1.png', show_shapes=True)\n","  model.summary()\n","  return model\n"]},{"cell_type":"code","source":[],"metadata":{"id":"f3X3WbSmbO2F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxHz0Mwim5Q9"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"ck2S4qtzj5wa","executionInfo":{"status":"error","timestamp":1691342665823,"user_tz":180,"elapsed":3903,"user":{"displayName":"Leonardo Barbosa","userId":"06345230168258917960"}},"outputId":"7c72c863-59ea-4f3a-a507-bf8fcaba5086"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6d402ef021ae>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Escolha entre comecar treino do zero ou continuar o treino de onde parou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#model = load_model(\"unet1.h5\");\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'unet' is not defined"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","#Escolha entre comecar treino do zero ou continuar o treino de onde parou\n","model=unet()\n","#model = load_model(\"unet1.h5\");\n","\n","\n","#history=model.fit(ax, ay, batch_size=1, epochs=100, verbose=2, validation_data=(vx,vy));\n","\n","\n","\n","batch_size=1\n","reduce_lr = ReduceLROnPlateau(monitor='loss',\n","factor=0.9, patience=1, min_lr=0.0000000001, verbose=True)\n","\n","\n","#history=model.fit(datagen.flow(ax,ay,batch_size=batch_size),epochs=100, verbose=2, validation_data=(vx, vy),callbacks=[reduce_lr])\n","\n","\n","history=model.fit(ax, ay, batch_size=3, epochs=25, verbose=2, validation_data=(vx,vy));\n","model.save(\"/content/drive/MyDrive/unet5.h5\");"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTIgZjNcE27-"},"outputs":[],"source":["#impHistoria(history); model.save(\"/content/drive/MyDrive/unet1.h5\");\n","impHistoria(history);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Sht9ymTdqUG"},"outputs":[],"source":["score = model.evaluate(ax, ay, verbose=0); print('Training loss:', score)\n","score = model.evaluate(vx, vy, verbose=0); print('Validation loss:', score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i2NVfhstlTF3"},"outputs":[],"source":["#unet-pred1.py\n","#Faz segmentacao de elipses e retangulos usando rede gerada pelo unet-train1.py\n","from PIL import Image\n","import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n","import cv2; import numpy as np; np.random.seed(7)\n","import tensorflow.keras as keras\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import Dropout, Conv2D, Conv2DTranspose\n","from tensorflow.keras import optimizers\n","import sys; from sys import argv\n","from matplotlib import pyplot as plt\n","\n","#<<<<<<<<<<<<<<<<<<< main <<<<<<<<<<<<<<<<<<<<<<\n","bdDir = \"\"\n","outDir = \".\"; os.chdir(outDir)\n","nome=\"zz\"\n","#inImgX = nome+\"x.png\"; inImgY = nome+\"y.png\"\n","inImgX=\"/content/drive/MyDrive/Colab Notebooks/dataset_artigobase/HeLa/train/DIC-C2DH-HeLa/01/t010.tif\"\n","inImgY=\"/content/drive/MyDrive/Colab Notebooks/dataset_artigobase/HeLa/train/DIC-C2DH-HeLa/01_ST/SEG/man_seg010.tif\"\n","outImgG=nome+\"g.png\"; outImgB =nome+\"saida.png\"\n","arquivoRede = \"/content/drive/MyDrive/unet1.h5\"\n","\n","model = load_model(os.path.join(outDir,arquivoRede))\n","QX=cv2.imread(os.path.join(bdDir,inImgX),0)\n","QY=cv2.imread(os.path.join(bdDir,inImgY),0)\n","\n","#im.show()\n","#QY= np.array(QY)\n","\n","print(QY)\n","nl=QX.shape[0]; nc=QX.shape[1]\n","#print(str(nl) +' '+ str(nc))\n","qx=np.float32(QX)/255.0 #Entre 0 e +1\n","qx2=qx\n","qx=qx.reshape(1, nl, nc, 1)\n","\n","qp=model.predict(qx); qp=qp.reshape(nl,nc) # entre 0 e +1\n","\n","QPG=255.0*qp; QPG=np.clip(QPG,0,255) # Entre 0 e 255\n","QPG=np.uint8(QPG); cv2.imwrite(os.path.join(outDir,outImgG),qp)\n","\n","QPB=np.zeros((nl,nc),dtype='uint8'); QPB[ qp>=0.02] = 255\n","cv2.imwrite(os.path.join(outDir,outImgB),QPB)\n","\n","f = plt.figure()\n","#f.add_subplot(1,4,1); plt.imshow(QX,cmap=\"gray\"); plt.axis('off')\n","f.add_subplot(1,2,1); plt.imshow(QY*50000,cmap=\"gray\"); plt.axis('off')\n","#f.add_subplot(1,4,3); plt.imshow(QPB,cmap=\"gray\"); plt.axis('off')\n","f.add_subplot(1,2,2); plt.imshow(qp*255/.16720633,cmap=\"gray\"); plt.axis('off')\n","plt.show(block=True)\n","\n","print(QY.max())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjVXp5Tc6fFG"},"outputs":[],"source":["vx[12].mean()\n","vy[13].max()\n","\n","img1=vx[7]\n","img2=vy[7]\n","\n","f = plt.figure()\n","f.add_subplot(1,4,1); plt.imshow(img1,cmap=\"gray\"); plt.axis('off')\n","f.add_subplot(1,4,2); plt.imshow(img2,cmap=\"gray\"); plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fcZgWEcMEL8D"},"outputs":[],"source":["255/.02966377"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPSzcH8N721N"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyIA4KnDxljY"},"outputs":[],"source":["def get_iou(ground_truth, pred):\n","    # coordinates of the area of intersection.\n","    ix1 = np.maximum(ground_truth[0], pred[0])\n","    iy1 = np.maximum(ground_truth[1], pred[1])\n","    ix2 = np.minimum(ground_truth[2], pred[2])\n","    iy2 = np.minimum(ground_truth[3], pred[3])\n","\n","    # Intersection height and width.\n","    i_height = np.maximum(iy2 - iy1 + 1, np.array(0.))\n","    i_width = np.maximum(ix2 - ix1 + 1, np.array(0.))\n","\n","    area_of_intersection = i_height * i_width\n","\n","    # Ground Truth dimensions.\n","    gt_height = ground_truth[3] - ground_truth[1] + 1\n","    gt_width = ground_truth[2] - ground_truth[0] + 1\n","\n","    # Prediction dimensions.\n","    pd_height = pred[3] - pred[1] + 1\n","    pd_width = pred[2] - pred[0] + 1\n","\n","    area_of_union = gt_height * gt_width + pd_height * pd_width - area_of_intersection\n","\n","    iou = area_of_intersection / area_of_union\n","\n","    return iou"]},{"cell_type":"code","source":["  from tensorflow.keras.utils import plot_model\n","\n","plot_model(model, to_file='unet-train1.png', show_shapes=True)\n"],"metadata":{"id":"XxgW8qmHDKNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc=0\n","nl,nc=512,512\n","print(np.shape(qp))\n","for i in range(0,20):\n","  qx=vx[i].reshape(1, nl, nc, 1)\n","  qp=model.predict(qx); qp=qp.reshape(nl,nc) # entre 0 e +1\n","\n","  acc += get_iou(vy[i],qp).mean()"],"metadata":{"id":"JPSmsY9kgxSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc/21"],"metadata":{"id":"S4lhun7_lY3a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_iou(a, b, epsilon=1e-5):\n","    \"\"\" Given two boxes `a` and `b` defined as a list of four numbers:\n","            [x1,y1,x2,y2]\n","        where:\n","            x1,y1 represent the upper left corner\n","            x2,y2 represent the lower right corner\n","        It returns the Intersect of Union score for these two boxes.\n","\n","    Args:\n","        a:          (list of 4 numbers) [x1,y1,x2,y2]\n","        b:          (list of 4 numbers) [x1,y1,x2,y2]\n","        epsilon:    (float) Small value to prevent division by zero\n","\n","    Returns:\n","        (float) The Intersect of Union score.\n","    \"\"\"\n","    # COORDINATES OF THE INTERSECTION BOX\n","    x1 = max(a[0], b[0])\n","    y1 = max(a[1], b[1])\n","    x2 = min(a[2], b[2])\n","    y2 = min(a[3], b[3])\n","\n","    # AREA OF OVERLAP - Area where the boxes intersect\n","    width = (x2 - x1)\n","    height = (y2 - y1)\n","    # handle case where there is NO overlap\n","    if (width<0) or (height <0):\n","        return 0.0\n","    area_overlap = width * height\n","\n","    # COMBINED AREA\n","    area_a = (a[2] - a[0]) * (a[3] - a[1])\n","    area_b = (b[2] - b[0]) * (b[3] - b[1])\n","    area_combined = area_a + area_b - area_overlap\n","\n","    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n","    iou = area_overlap / (area_combined+epsilon)\n","    return iou"],"metadata":{"id":"oUS-_zdjHgu_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(np.shape(qp))"],"metadata":{"id":"8sqkm5IToE_X"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}